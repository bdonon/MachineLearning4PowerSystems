{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82af1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ML4PS as ml\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ca1a1",
   "metadata": {},
   "source": [
    "# Loading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../data/case14'\n",
    "\n",
    "normalizer = ml.Normalizer(data_dir = data_dir, backend_name = 'pandapower')\n",
    "\n",
    "interface = ml.Interface(data_dir = data_dir,\n",
    "    backend_name = 'pandapower', batch_size = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3168055",
   "metadata": {},
   "source": [
    "# Defining a Hyper Heterogeneous Multi Graph Neural Ordinary Differential Equation (H2MGNODE)\n",
    "The H2MGNODE combines the Hyper Heterogeneous Multi Graph Neural Network and Neural Ordinary Differential Equations.\n",
    "\n",
    "It uses an architecture very similar to the H2MGNN architecture, but it solves the latent system of equations using a variable timestep method. Contrarily to the fully connected, you do not have to specify the amount of objects of each class at the initialization. It will take as input both the addresses $a$ and the features $x$. One should tell the H2MGNODE which addresses it should be using to propagate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd87d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = {}\n",
    "addresses['bus']       = ['id']\n",
    "addresses['gen']       = ['bus']\n",
    "addresses['load']      = ['bus']\n",
    "addresses['shunt']     = ['bus']\n",
    "addresses['ext_grid']  = ['bus']\n",
    "addresses['line']      = ['from_bus', 'to_bus']\n",
    "addresses['trafo']     = ['hv_bus', 'lv_bus']\n",
    "addresses['poly_cost'] = ['element']\n",
    "\n",
    "input_features = {}\n",
    "input_features['bus']       = ['in_service', 'max_vm_pu', 'min_vm_pu', 'vn_kv']\n",
    "input_features['load']      = ['const_i_percent', 'const_z_percent', 'controllable', 'in_service', \n",
    "                               'p_mw', 'q_mvar', 'scaling', 'sn_mva']\n",
    "input_features['gen']       = ['in_service', 'p_mw', 'scaling', 'sn_mva', 'vm_pu', 'slack', 'max_p_mw', \n",
    "                               'min_p_mw', 'max_q_mvar', 'min_q_mvar', 'slack_weight']\n",
    "input_features['shunt']     = ['q_mvar', 'p_mw', 'vn_kv', 'step', 'max_step', 'in_service']\n",
    "input_features['ext_grid']  = ['in_service', 'va_degree', 'vm_pu', 'max_p_mw', 'min_p_mw', 'max_q_mvar',\n",
    "                               'min_q_mvar', 'slack_weight']\n",
    "input_features['line']      = ['c_nf_per_km', 'df', 'g_us_per_km', 'in_service', 'length_km', 'max_i_ka',\n",
    "                               'max_loading_percent', 'parallel', 'r_ohm_per_km', 'x_ohm_per_km']\n",
    "input_features['trafo']     = ['df', 'i0_percent', 'in_service', 'max_loading_percent', 'parallel', \n",
    "                               'pfe_kw', 'shift_degree', 'sn_mva', 'tap_max', 'tap_neutral', 'tap_min', \n",
    "                               'tap_phase_shifter', 'tap_pos', 'tap_side', 'tap_step_degree', \n",
    "                               'tap_step_percent', 'vn_hv_kv', 'vn_lv_kv', 'vk_percent', 'vkr_percent']\n",
    "input_features['poly_cost'] = ['cp0_eur', 'cp1_eur_per_mw', 'cp2_eur_per_mw2', 'cq0_eur', \n",
    "                               'cq1_eur_per_mvar', 'cq2_eur_per_mvar2']\n",
    "\n",
    "output_features = {}\n",
    "output_features['bus'] = ['res_vm_pu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ec1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2mgnode = ml.H2MGNODE(addresses=addresses, \n",
    "                       input_features = input_features, \n",
    "                       output_features = output_features, \n",
    "                       hidden_dimensions = [64], \n",
    "                       latent_dimension = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d611056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessor:\n",
    "    def __call__(self, y):\n",
    "        return {'bus': {'res_vm_pu': self.bus_v_mag(y['bus']['res_vm_pu'])}}\n",
    "    def bus_v_mag(self, y):\n",
    "        return 1.+y\n",
    "postprocessor = PostProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params, init_state, y_truth):\n",
    "    y_hat = h2mgnode.solve_and_decode_batch(params, init_state)\n",
    "    y_post = postprocessor(y_hat)\n",
    "    return ml.mean((y_truth['bus']['res_vm_pu'] - y_post['bus']['res_vm_pu'])**2)\n",
    "\n",
    "@ml.jit\n",
    "def update(params, init_state, y_truth, opt_state):\n",
    "    value, grads = ml.value_and_grad(loss)(params, init_state, y_truth)\n",
    "    opt_state = opt_update(0, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54e588",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 3e-4\n",
    "opt_init, opt_update, get_params = ml.optimizers.adam(step_size)\n",
    "opt_state = opt_init(h2mgnode.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b7736",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    for a, x, nets in interface.get_train_batch():\n",
    "        interface.run_load_flow_batch(nets)\n",
    "        y_truth = interface.get_features_dict(nets, {'bus':['res_vm_pu']})\n",
    "        \n",
    "        x_norm = normalizer(x)\n",
    "        init_state = h2mgnode.init_state_batch(a, x_norm)\n",
    "        h2mgnode.weights, opt_state, train_loss = update(h2mgnode.weights,\n",
    "            init_state, y_truth, opt_state)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "    \n",
    "    # Compute metrics over validation set\n",
    "    val_losses = []\n",
    "    for a, x, nets in interface.get_val_batch():\n",
    "        interface.run_load_flow_batch(nets)\n",
    "        y_truth = interface.get_features_dict(nets, {'bus':['res_vm_pu']})\n",
    "    \n",
    "        x_norm = normalizer(x)\n",
    "        init_state = h2mgnode.init_state_batch(a, x_norm)\n",
    "        val_loss = loss(h2mgnode.weights, init_state, y_truth)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "    print(\"Epoch {}\".format(epoch))\n",
    "    print(\"    Train mean loss = {:.2e}\".format(np.mean(train_losses)))\n",
    "    print(\"    Validation mean loss = {:.2e}\".format(np.mean(val_losses)))\n",
    "    \n",
    "# saving the trained method\n",
    "h2mgnode.save('h2mgnode.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

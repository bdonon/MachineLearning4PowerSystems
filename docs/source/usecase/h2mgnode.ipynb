{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48358519",
   "metadata": {},
   "source": [
    "# Training a graph neural network to imitate a simulator\n",
    "\n",
    "In this notebook, we explain how to use our package to train a simple neural network to imitate the output of an AC power flow simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea6148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "mpl.rcParams['axes.prop_cycle'] = plt.cycler(\"color\", plt.cm.tab10.colors)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../../..')\n",
    "import ml4ps as mp\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7b304",
   "metadata": {},
   "source": [
    "## Downloading a dataset\n",
    "\n",
    "First of all, we need to download a dataset. We propose to download a small dataset of power grids derived from the case60nordic file (also known as nordic32), randomly generated using [powerdatagen](https://github.com/bdonon/powerdatagen).\n",
    "\n",
    "The dataset is available on zenodo [here](https://zenodo.org/record/7077699). The following code downloads the dataset if it is not already here. Please be patient, as it may take several minutes (not more than 10 minutes though).\n",
    "\n",
    "If you have already downloaded the dataset, then this does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9d5953",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d data/case60/ ]\n",
    "then\n",
    "    zenodo_get '10.5281/zenodo.7077699' -o data/\n",
    "    unzip -qq data/case60.zip -d data/\n",
    "    rm data/case60.zip data/md5sums.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b57145",
   "metadata": {},
   "source": [
    "## Backend instantation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528dbef",
   "metadata": {},
   "source": [
    "We need to import a backend, which will serve to read power grid data. In some more complex problem, it will be used to perform power grid simulations.\n",
    "\n",
    "In this case, we are considering a dataset of .json files that can be read by pandapower. We thus choose the backend that uses pandapower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf5b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = mp.PandaPowerBackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08065c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../../../../powerdatagen/data/case60nordic_small/train'\n",
    "train_dir_pkl = '../../../../powerdatagen/data/case60nordic_small/train_pkl'\n",
    "\n",
    "#train_dir = 'data/case60/train'\n",
    "#train_dir_pkl = 'data/case60/train_pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a764a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mp.pickle_dataset(train_dir, train_dir_pkl, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693962a6",
   "metadata": {},
   "source": [
    "## Building a normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ae78f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading power grids.: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 19.71it/s]\n",
      "Extracting features.: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 120.57it/s]\n"
     ]
    }
   ],
   "source": [
    "normalizer = mp.Normalizer(data_dir=train_dir, backend=backend, n_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45d8d7",
   "metadata": {},
   "source": [
    "## Building a train set and a data loader\n",
    "\n",
    "The normalizer is fed to the data loader, so that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62cc8716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the dataset in memory.: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:54<00:00, 182.67it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set = mp.PowerGridDataset(data_dir=train_dir_pkl, backend=backend, normalizer=normalizer,\n",
    "                                pickle=True, load_in_memory=True)\n",
    "#train_set = mp.PowerGridDataset(data_dir=train_dir, backend=backend, normalizer=normalizer)\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=mp.collate_power_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd4687",
   "metadata": {},
   "source": [
    "## Building a Hyper Heterogeneous Multi Graph Neural Ordinary Differential Equation\n",
    "\n",
    "First of all, we need to tell the neural network which features it should take as input, and wich features we want it to output. In this case, we want the neural network to output predictions for the voltage magnitude at each bus.\n",
    "\n",
    "Moreover, since we are working with a graph neural network, we need to pass the information of where the GNN should look for object addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d8f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_input_feature_names = {\n",
    "    'bus': ['in_service', 'max_vm_pu', 'min_vm_pu', 'vn_kv'],\n",
    "    'load': ['const_i_percent', 'const_z_percent', 'controllable', 'in_service', \n",
    "                                'p_mw', 'q_mvar', 'scaling', 'sn_mva'],\n",
    "    'sgen': ['controllable', 'in_service', 'p_mw', 'q_mvar', 'scaling', 'sn_mva',\n",
    "                                'current_source'],\n",
    "    'gen': ['controllable', 'in_service', 'p_mw', 'scaling', 'sn_mva', 'vm_pu',\n",
    "                'slack', 'max_p_mw', 'min_p_mw', 'max_q_mvar', 'min_q_mvar', 'slack_weight'],\n",
    "    'shunt': ['q_mvar', 'p_mw', 'vn_kv', 'step', 'max_step', 'in_service'],\n",
    "    'ext_grid': ['in_service', 'va_degree', 'vm_pu', 'max_p_mw', 'min_p_mw', 'max_q_mvar',\n",
    "                                'min_q_mvar', 'slack_weight'],\n",
    "    'line': ['c_nf_per_km', 'df', 'g_us_per_km', 'in_service', 'length_km', 'max_i_ka',\n",
    "                                'max_loading_percent', 'parallel', 'r_ohm_per_km', 'x_ohm_per_km'],\n",
    "    'trafo': ['df', 'i0_percent', 'in_service', 'max_loading_percent', 'parallel', \n",
    "                                'pfe_kw', 'shift_degree', 'sn_mva', 'tap_max', 'tap_neutral', 'tap_min',\n",
    "                                'tap_phase_shifter', 'tap_pos', 'tap_side', 'tap_step_degree', \n",
    "                                'tap_step_percent', 'vn_hv_kv', 'vn_lv_kv', 'vk_percent', 'vkr_percent']\n",
    "}\n",
    "local_output_feature_names = {'bus': ['res_vm_pu']}\n",
    "local_address_names = {\n",
    "    'bus': ['id'],\n",
    "    'load': ['bus'],\n",
    "    'sgen': ['bus'],\n",
    "    'gen': ['bus'],\n",
    "    'shunt': ['bus'],\n",
    "    'ext_grid': ['bus'],\n",
    "    'line': ['from_bus', 'to_bus'],\n",
    "    'trafo': ['hv_bus', 'lv_bus']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74c090",
   "metadata": {},
   "source": [
    "Since we are working with a fully connected neural network, we need to pass a sample to the constructor, so that  it knows how many object of each class will be present in the data. This is due to the fact that fully connected neural networks can only take vector data as input. By telling the neural network the amount of objects, it is able to initialize its weights using the right dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489e1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, nets = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d52e7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2mgnode = mp.H2MGNODE(x=x,\n",
    "                       local_input_feature_names=local_input_feature_names,\n",
    "                       local_output_feature_names=local_output_feature_names,\n",
    "                       local_address_names=local_address_names,\n",
    "                       phi_hidden_dimensions=[64],\n",
    "                       psi_hidden_dimensions=[32, 32],\n",
    "                       phi_scale_init=[[1e-2, 1e-2], [1e-2, 0]],\n",
    "                       psi_scale_init=[[1e-2, 1e-2], [1e-2, 1e-2], [1e-2, 0]],\n",
    "                       latent_dimension=8\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cfc76",
   "metadata": {},
   "source": [
    "In addition, we need to specify post-processing functions, so that our model starts its training in a reasonable range. Here, we know that voltage magnitudes should be around 1 p.u., so we post-process the neural network output by adding an offset of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b37253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions = {'bus': {'res_vm_pu': [mp.AffineTransform(offset=1.)]}}\n",
    "# postprocessor = mp.PostProcessor(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b46fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = mp.PostProcessor(config={'bus':{'res_vm_pu':[['affine', {'offset':1.}]]}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48be16",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7174e",
   "metadata": {},
   "source": [
    "Here, we propose to train our neural network using the Adam optimizer. The loss function is the squared distance between the neural network prediction and the output of the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eeff6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.example_libraries import optimizers\n",
    "\n",
    "learning_rate = 3e-3#3e-4#3e-4#3e-4#\n",
    "opt_init, opt_update, get_params = optimizers.adam(learning_rate)#, b1=0.9999, b2=0.99999)\n",
    "opt_state = opt_init(h2mgnode.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee84ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(params, start_state, y):\n",
    "    y_hat = h2mgnode.solve_and_decode_batch(params, start_state)\n",
    "    y_post = postprocessor(y_hat)\n",
    "    return jnp.mean((y_post['bus']['res_vm_pu'] - y['bus']['res_vm_pu'])**2)\n",
    "\n",
    "@jax.jit\n",
    "def update_jit(params, start_state, y, opt_state, step):\n",
    "    loss, grads = jax.value_and_grad(loss_function)(params, start_state, y)\n",
    "    opt_state = opt_update(step, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, loss\n",
    "#@jax.jit\n",
    "def update(params, x, y, opt_state, step):\n",
    "    start_state = h2mgnode.init_state_batch(x)\n",
    "    return update_jit(params, start_state, y, opt_state, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a642fbe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd88a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = -1\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de33bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir = '../../../../powerdatagen/data/case60nordic/test'\n",
    "# #test_dir = 'data/case60/train'\n",
    "# test_set = mp.PowerGridDataset(data_dir=test_dir, backend=backend, normalizer=normalizer)\n",
    "# test_loader = DataLoader(test_set,\n",
    "#                           batch_size=8,\n",
    "#                           shuffle=True,\n",
    "#                           num_workers=2,\n",
    "#                           collate_fn=mp.collate_power_grid)\n",
    "# x_fixed, nets = next(iter(test_loader))\n",
    "# init_state = h2mgnode.init_state_batch(x_fixed)\n",
    "\n",
    "# from jax.experimental.ode import odeint\n",
    "# start_and_end_times = jnp.linspace(0., 1., 50)\n",
    "\n",
    "# def odenet(params, init_state):\n",
    "#     intermediate_states = odeint(h2mgnode.dynamics, init_state, start_and_end_times, params)\n",
    "#     return intermediate_states\n",
    "\n",
    "# batched_odenet = jax.vmap(odenet, in_axes=(None, 0))\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# #os.mkdir('trajectory')\n",
    "# #os.mkdir('output')\n",
    "\n",
    "# y_truth = backend.get_data_batch(nets, feature_names={'bus': ['res_vm_pu']})\n",
    "# y_truth = np.reshape(y_truth['bus']['res_vm_pu'], [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27af40b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 5.34e-04:   4%|█████████                                                                                                                                                                                                                                              | 46/1250 [00:32<14:04,  1.43it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#backend.run_batch(nets) # AC power flow simulation \u001b[39;00m\n\u001b[1;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mget_data_batch(nets, feature_names\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbus\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mres_vm_pu\u001b[39m\u001b[38;5;124m'\u001b[39m]}) \u001b[38;5;66;03m# Ground truth extraction\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m h2mgnode\u001b[38;5;241m.\u001b[39mparams, opt_state, loss \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh2mgnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Loss = \u001b[39m\u001b[38;5;132;01m{:.2e}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, loss))\n\u001b[1;32m     10\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[0;32mIn [15], line 14\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, opt_state, step)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(params, x, y, opt_state, step):\n\u001b[1;32m     13\u001b[0m     start_state \u001b[38;5;241m=\u001b[39m h2mgnode\u001b[38;5;241m.\u001b[39minit_state_batch(x)\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupdate_jit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/postdoc/code/ml4ps/venv/lib/python3.10/site-packages/jax/example_libraries/optimizers.py:119\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(data, xs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# The implementation here basically works by flattening pytrees. There are two\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# levels of pytrees to think about: the pytree of params, which we can think of\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# as defining an \"outer pytree\", and a pytree produced by applying init_fun to\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# each leaf of the params pytree, which we can think of as the \"inner pytrees\".\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# Since pytrees can be flattened, that structure is isomorphic to a list of\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# lists (with no further nesting).\u001b[39;00m\n\u001b[1;32m    114\u001b[0m OptimizerState \u001b[38;5;241m=\u001b[39m namedtuple(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizerState\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m                             [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpacked_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtree_def\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubtree_defs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    116\u001b[0m register_pytree_node(\n\u001b[1;32m    117\u001b[0m     OptimizerState,\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m xs: ((xs\u001b[38;5;241m.\u001b[39mpacked_state,), (xs\u001b[38;5;241m.\u001b[39mtree_def, xs\u001b[38;5;241m.\u001b[39msubtree_defs)),\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m data, xs: OptimizerState(xs[\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m1\u001b[39m]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    122\u001b[0m Array \u001b[38;5;241m=\u001b[39m Any\n\u001b[1;32m    123\u001b[0m Params \u001b[38;5;241m=\u001b[39m Any  \u001b[38;5;66;03m# Parameters are arbitrary nests of `jnp.ndarrays`.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for x, nets in (pbar := tqdm.tqdm(train_loader)):\n",
    "        step += 1\n",
    "        \n",
    "        #backend.run_batch(nets) # AC power flow simulation \n",
    "        y = backend.get_data_batch(nets, feature_names={'bus': ['res_vm_pu']}) # Ground truth extraction\n",
    "        h2mgnode.params, opt_state, loss = update(h2mgnode.params, x, y, opt_state, step)\n",
    "        \n",
    "        pbar.set_description(\"Epoch {}, Loss = {:.2e}\".format(epoch, loss))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbb7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, nets = next(iter(train_loader))\n",
    "# y = backend.get_data_batch(nets, feature_names={'bus': ['res_vm_pu']})\n",
    "# for _ in tqdm.tqdm(range(10000)):\n",
    "#     h2mgnode.params, opt_state, loss = update(h2mgnode.params, x, y, opt_state, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eba967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses, linewidth=0.2)\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631172cf",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "We now wish to take a look at how well our model performs on the test data. In this notebook we propose to plot the ground truth versus the prediction for a sample of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a77b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../../../../powerdatagen/data/case60nordic_small/test'\n",
    "#test_dir = 'data/case60/train'\n",
    "test_set = mp.PowerGridDataset(data_dir=test_dir, backend=backend, normalizer=normalizer)\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=mp.collate_power_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, nets = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9382c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "y_hat = h2mgnode.forward_batch(h2mgnode.params, x)\n",
    "y_post = postprocessor(y_hat)\n",
    "y_post = np.reshape(y_post['bus']['res_vm_pu'], [-1])\n",
    "\n",
    "# Get ground truth\n",
    "y_truth = backend.get_data_batch(nets, feature_names={'bus': ['res_vm_pu']})\n",
    "y_truth = np.reshape(y_truth['bus']['res_vm_pu'], [-1])\n",
    "\n",
    "# Compare results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_truth, y_post, s=0.4)\n",
    "plt.xlabel('Ground truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "np.corrcoef(y_truth, y_post)[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a4d62",
   "metadata": {},
   "source": [
    "## Bonus : visualization of latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.experimental.ode import odeint\n",
    "start_and_end_times = jnp.linspace(0., 1., 100)\n",
    "\n",
    "def odenet(params, init_state):\n",
    "    intermediate_states = odeint(h2mgnode.dynamics, init_state, start_and_end_times, params,\n",
    "                                rtol=1e-4, atol=1e-4)\n",
    "    return intermediate_states\n",
    "\n",
    "batched_odenet = jax.vmap(odenet, in_axes=(None, 0))\n",
    "    \n",
    "x, nets = next(iter(test_loader))\n",
    "init_state = h2mgnode.init_state_batch(x)\n",
    "intermediate_states = batched_odenet(h2mgnode.params, init_state)\n",
    "\n",
    "y_plot = intermediate_states['h_v'][0,:,:,0]\n",
    "plt.plot(start_and_end_times, y_plot)\n",
    "plt.show()\n",
    "\n",
    "x_plot = intermediate_states['h_v'][0,:,:,0]\n",
    "y_plot = intermediate_states['h_v'][0,:,:,1]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.show()\n",
    "\n",
    "x_plot = intermediate_states['h_v'][0,:,:,0]\n",
    "y_plot = intermediate_states['h_v'][0,:,:,2]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.show()\n",
    "\n",
    "x_plot = intermediate_states['h_v'][0,:,:,2]\n",
    "y_plot = intermediate_states['h_v'][0,:,:,1]\n",
    "plt.plot(x_plot, y_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0103bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_and_end_times = jnp.array([0.,1.])\n",
    "#start_and_end_times = jnp.linspace(0., 1., 50)\n",
    "\n",
    "\n",
    "def odenet_(params, init_state, atol, rtol):\n",
    "    intermediate_states = odeint(h2mgnode.dynamics, init_state, start_and_end_times, params,\n",
    "                                rtol=rtol, atol=atol)\n",
    "    return intermediate_states\n",
    "\n",
    "batched_odenet_ = jax.vmap(odenet_, in_axes=(None, 0))\n",
    "    \n",
    "def loss_function(params, start_state, y):\n",
    "    y_hat = h2mgnode.solve_and_decode(params, start_state)\n",
    "    y_post = postprocessor(y_hat)\n",
    "    return jnp.mean((y_post['bus']['res_vm_pu'] - y['bus']['res_vm_pu'])**2)\n",
    "\n",
    "    \n",
    "x, nets = test_set.__getitem__(0)\n",
    "init_state = h2mgnode.init_state(x)\n",
    "y = backend.get_data_network(nets, feature_names={'bus': ['res_vm_pu']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e77a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, grads = jax.value_and_grad(loss_function)(h2mgnode.params, init_state, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a968a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25023675",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_states = odeint(h2mgnode.dynamics, init_state, start_and_end_times,\n",
    "                             h2mgnode.params, rtol=1e-12, atol=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e87247",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_states['h_v'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_states['h_v'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbd2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.mkdir('latent_traj')\n",
    "for t in range(101):\n",
    "    x_plot = intermediate_states['h_v'][0,:t,:,0]\n",
    "    y_plot = intermediate_states['h_v'][0,:t,:,1]\n",
    "    plt.figure(figsize=[10,10], dpi=200)\n",
    "    plt.plot(x_plot, y_plot)\n",
    "    plt.axis('off')\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.savefig('latent_traj/step_{}'.format(t))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cf57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h2mgnode.save('model_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b05263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

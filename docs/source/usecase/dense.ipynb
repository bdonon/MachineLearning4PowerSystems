{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48358519",
   "metadata": {},
   "source": [
    "# Training a dense neural network to imitate a simulator\n",
    "\n",
    "In this notebook, we explain how to use our package to train a simple neural network to imitate the output of an AC power flow simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea6148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys; sys.path.insert(0, '../..')\n",
    "import ml4ps as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7b304",
   "metadata": {},
   "source": [
    "## Downloading a dataset\n",
    "\n",
    "First of all, we need to download a dataset. We propose to download a small dataset of power grids derived from the case60nordic file (also known as nordic32), randomly generated using [powerdatagen](https://github.com/bdonon/powerdatagen).\n",
    "\n",
    "The dataset is available on zenodo [here](https://zenodo.org/record/7077699). The following code downloads the dataset if it is not already here. Please be patient, as it may take several minutes (not more than 10 minutes though).\n",
    "\n",
    "If you have already downloaded the dataset, then this does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab9d5953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Title: case60nordic random power grid dataset\n",
      "Keywords: power systems\n",
      "Publication date: 2022-09-14\n",
      "DOI: 10.5281/zenodo.7077699\n",
      "Total size: 194.3 MB\n",
      "\n",
      "Link: https://zenodo.org/api/files/aec5b643-ca48-4caa-9bbb-b5736e098608/case60.zip   size: 194.3 MB\n",
      "\n",
      "Checksum is correct. (056894b73788a4cbe856c2cee4deb13e)\n",
      "All files have been downloaded.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ ! -d data/case60/ ]\n",
    "then\n",
    "    zenodo_get '10.5281/zenodo.7077699' -o data/\n",
    "    unzip -qq data/case60.zip -d data/\n",
    "    rm data/case60.zip data/md5sums.txt\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b57145",
   "metadata": {},
   "source": [
    "## Backend instantation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7528dbef",
   "metadata": {},
   "source": [
    "We need to import a backend, which will serve to read power grid data. In some more complex problem, it will be used to perform power grid simulations.\n",
    "\n",
    "In this case, we are considering a dataset of .json files that can be read by pandapower. We thus choose the backend that uses pandapower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf5b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = mp.PandaPowerBackend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08065c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/case60/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693962a6",
   "metadata": {},
   "source": [
    "## Building a normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae78f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a Normalizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading power grids : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 20.62it/s]\n",
      "Extracting features : 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 108.83it/s]\n",
      "Building normalizing functions : 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 342.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer ready to normalize !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "normalizer = mp.Normalizer(data_dir=train_dir, backend=backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c45d8d7",
   "metadata": {},
   "source": [
    "## Building a train set and a data loader\n",
    "\n",
    "The normalizer is fed to the data loader, so that ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62cc8716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mp.PowerGridDataset(data_dir=train_dir, backend=backend, normalizer=normalizer)\n",
    "train_loader = DataLoader(train_set,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=mp.collate_power_grid,\n",
    "                          prefetch_factor=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd4687",
   "metadata": {},
   "source": [
    "## Building a Fully Connected neural network\n",
    "\n",
    "First of all, we need to tell the neural network which features it should take as input, and wich features we want it to output. In this case, we want the neural network to output predictions for the voltage magnitude at each bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13d8f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_feature_names = {'load': ['p_mw', 'q_mvar'], 'gen': ['p_mw', 'vm_pu'], 'ext_grid': ['vm_pu']}\n",
    "output_feature_names = {'bus': ['res_vm_pu']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec74c090",
   "metadata": {},
   "source": [
    "Since we are working with a fully connected neural network, we need to pass a sample to the constructor, so that  it knows how many object of each class will be present in the data. This is due to the fact that fully connected neural networks can only take vector data as input. By telling the neural network the amount of objects, it is able to initialize its weights using the right dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d52e7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, x, nets = next(iter(train_loader))\n",
    "\n",
    "fully_connected = mp.FullyConnected(\n",
    "    x=x,\n",
    "    input_feature_names=input_feature_names,\n",
    "    output_feature_names=output_feature_names,\n",
    "    hidden_dimensions=[1024,1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845cfc76",
   "metadata": {},
   "source": [
    "In addition, we need to specify post-processing functions, so that our model starts its training in a reasonable range. Here, we know that voltage magnitudes should be around 1 p.u., so we post-process the neural network output by adding an offset of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b37253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {'bus': {'res_vm_pu': [mp.AffineTransform(offset=1.)]}}\n",
    "postprocessor = mp.PostProcessor(functions=functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48be16",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7174e",
   "metadata": {},
   "source": [
    "Here, we propose to train our neural network using the Adam optimizer. The loss function is the squared distance between the neural network prediction and the output of the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeff6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.example_libraries import optimizers\n",
    "\n",
    "learning_rate = 3e-4\n",
    "opt_init, opt_update, get_params = optimizers.adam(learning_rate)\n",
    "opt_state = opt_init(fully_connected.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aee84ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(params, x, y):\n",
    "    y_hat = fully_connected.batch_forward(params, x)\n",
    "    y_post = postprocessor(y_hat)\n",
    "    loss = jnp.mean((y_post['bus']['res_vm_pu'] - y['bus']['res_vm_pu'])**2)\n",
    "    return loss\n",
    "\n",
    "@jax.jit\n",
    "def update(params, x, y, opt_state, step):\n",
    "    loss, grads = jax.value_and_grad(loss_function)(params, x, y)\n",
    "    opt_state = opt_update(step, grads, opt_state)\n",
    "    return get_params(opt_state), opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27af40b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 2.44e-04:  48%|███████████████████████████████████████████████████████████████████████████████████████▋                                                                                              | 602/1250 [03:02<03:16,  3.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a, x, nets \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_loader)):\n\u001b[1;32m      4\u001b[0m         step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m         backend\u001b[38;5;241m.\u001b[39mrun_batch(nets) \u001b[38;5;66;03m# AC power flow simulation \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/postdoc/code/ml4ps/venv/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/postdoc/code/ml4ps/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Documents/postdoc/code/ml4ps/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1359\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/postdoc/code/ml4ps/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1325\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1325\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1327\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/Documents/postdoc/code/ml4ps/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1163\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    933\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.6_2/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for epoch in range(2):\n",
    "    for a, x, nets in (pbar := tqdm.tqdm(train_loader)):\n",
    "        step += 1\n",
    "        \n",
    "        backend.run_batch(nets) # AC power flow simulation \n",
    "        y = backend.get_feature_batch(nets, feature_names={'bus':['res_vm_pu']}) # Ground truth extraction\n",
    "        fully_connected.weights, opt_state, loss = update(fully_connected.weights, x, y, opt_state, step)\n",
    "        \n",
    "        pbar.set_description(\"Epoch {}, Loss = {:.2e}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631172cf",
   "metadata": {},
   "source": [
    "## Testing the model\n",
    "\n",
    "We now wish to take a look at how well our model performs on the test data. In this notebook we propose to plot the ground truth versus the prediction for a sample of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a77b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'data/case60/test'\n",
    "test_set = mp.PowerGridDataset(data_dir=test_dir, backend=backend, normalizer=normalizer)\n",
    "test_loader = DataLoader(test_set,\n",
    "                          batch_size=8,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          collate_fn=mp.collate_power_grid,\n",
    "                          prefetch_factor=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5c7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, x, nets = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c9382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform prediction\n",
    "y_hat = fully_connected.batch_forward(fully_connected.weights, x)\n",
    "y_post = postprocessor(y_hat)\n",
    "y_post = np.reshape(y_post['bus']['res_vm_pu'], [-1])\n",
    "\n",
    "# Get ground truth\n",
    "y_truth = backend.get_feature_batch(nets, feature_names={'bus':['res_vm_pu']})\n",
    "y_truth = np.reshape(y_truth['bus']['res_vm_pu'], [-1])\n",
    "\n",
    "# Compare results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_truth, y_post)\n",
    "plt.xlabel('Ground truth')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699c48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
